{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Problem Overview :\n",
        "\n",
        "1. Goal: Demonstrate Hebbian learning for storing simple binary patterns.\n",
        "\n",
        "2. Dataset: Custom simple binary patterns (e.g., 3×3 or 4×4 matrices representing letters or shapes).\n",
        "\n",
        "3. Deliverable: Learned weight matrix and ability to recall stored patterns.\n",
        "\n",
        "<h3>Why Hebbian Learning?\n",
        "\n",
        "1. Based on the principle: \"Neurons that fire together, wire together.\"\n",
        "\n",
        "2. Updates weights based on correlation between input neurons.\n",
        "\n",
        "3. No backpropagation; simple local learning rule."
      ],
      "metadata": {
        "id": "DhzZ1rZ5zgVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Hebbian Learning Rule\n",
        "\n",
        "For a network of N neurons:\n",
        "\n",
        "                   W=p=1∑P​x(p)⋅x(p)T\n",
        "\n",
        "       x^(p) → input pattern vector\n",
        "       P → number of patterns\n",
        "       Weight matrix W is symmetric, with W[i,i] = 0 (no self-connection)\n",
        "Update / recall:\n",
        "\n",
        "                     y=sign(W⋅x)\n",
        "- Output y should reproduce the original pattern x."
      ],
      "metadata": {
        "id": "eAzS4xSPzyxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBclmLyvzSt6",
        "outputId": "15b73825-e8fa-4583-e0bb-0d191e19a16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Learned Weight Matrix:\n",
            "[[ 0.  0.  2. -2.  0. -2.  2.  0.  2.]\n",
            " [ 0.  0.  0.  0. -2.  0.  0.  2.  0.]\n",
            " [ 2.  0.  0. -2.  0. -2.  2.  0.  2.]\n",
            " [-2.  0. -2.  0.  0.  2. -2.  0. -2.]\n",
            " [ 0. -2.  0.  0.  0.  0.  0. -2.  0.]\n",
            " [-2.  0. -2.  2.  0.  0. -2.  0. -2.]\n",
            " [ 2.  0.  2. -2.  0. -2.  0.  0.  2.]\n",
            " [ 0.  2.  0.  0. -2.  0.  0.  0.  0.]\n",
            " [ 2.  0.  2. -2.  0. -2.  2.  0.  0.]]\n",
            "\n",
            "Pattern 1 Original: [ 1 -1  1 -1  1 -1  1 -1  1]\n",
            "Pattern 1 Recalled : [ 1. -1.  1. -1.  1. -1.  1. -1.  1.]\n",
            "\n",
            "Pattern 2 Original: [ 1  1  1 -1 -1 -1  1  1  1]\n",
            "Pattern 2 Recalled : [ 1.  1.  1. -1. -1. -1.  1.  1.  1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ Define Binary Patterns\n",
        "# -----------------------------\n",
        "# Example: 3x3 patterns flattened\n",
        "patterns = np.array([\n",
        "    [1, -1, 1,\n",
        "     -1, 1, -1,\n",
        "      1, -1, 1],  # Pattern A\n",
        "\n",
        "    [1, 1, 1,\n",
        "     -1, -1, -1,\n",
        "      1, 1, 1]   # Pattern B\n",
        "])\n",
        "\n",
        "num_neurons = patterns.shape[1]\n",
        "\n",
        "# -----------------------------\n",
        "# 2️⃣ Hebbian Learning\n",
        "# -----------------------------\n",
        "W = np.zeros((num_neurons, num_neurons))\n",
        "\n",
        "for p in patterns:\n",
        "    W += np.outer(p, p)\n",
        "\n",
        "# Remove self-connections\n",
        "np.fill_diagonal(W, 0)\n",
        "\n",
        "print(\"✅ Learned Weight Matrix:\")\n",
        "print(W)\n",
        "\n",
        "# -----------------------------\n",
        "# 3️⃣ Recall Patterns\n",
        "# -----------------------------\n",
        "def recall(input_pattern, W):\n",
        "    return np.sign(W @ input_pattern)\n",
        "\n",
        "for idx, p in enumerate(patterns):\n",
        "    recalled = recall(p, W)\n",
        "    print(f\"\\nPattern {idx+1} Original: {p}\")\n",
        "    print(f\"Pattern {idx+1} Recalled : {recalled}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Notebook Deliverables :\n",
        "\n",
        "1. Custom binary patterns\n",
        "\n",
        "2. Learned weight matrix (W)\n",
        "\n",
        "3. Recall demonstration for stored patterns\n",
        "\n",
        "4. Observations on perfect recall vs interference"
      ],
      "metadata": {
        "id": "lhjhWFhj1MhN"
      }
    }
  ]
}